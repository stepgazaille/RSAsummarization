{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "import os, struct\n",
    "from tensorflow.core.example import example_pb2\n",
    "import pyrouge\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmd = '/root/miniconda2/bin/python run_summarization.py --mode=decode --single_pass=1 --coverage=True --vocab_path=finished_files/vocab --log_root=log --exp_name=myexperiment --data_path=test/temp_file --max_enc_steps=4000'\n",
    "# generated_path = '/gttp/pointer-generator-tal/log/myexperiment/decode_test_4000maxenc_4beam_35mindec_100maxdec_ckpt-238410/'\n",
    "# cmd = cmd.split()\n",
    "\n",
    "vocab_path = '../data/DMQA/finished_files/vocab'\n",
    "log_root = 'log'\n",
    "exp_name = 'myexperiment'\n",
    "data_path= 'test/temp_file'\n",
    "max_enc_steps = 4000\n",
    "\n",
    "cmd = ['python',\n",
    "       'run_summarization.py',\n",
    "       '--mode=decode',\n",
    "       '--single_pass=1',\n",
    "       '--coverage=True',\n",
    "       '--vocab_path=' + vocab_path,\n",
    "       '--log_root=' + log_root,\n",
    "       '--exp_name=' + exp_name,\n",
    "       '--data_path=' + data_path,\n",
    "       '--max_enc_steps=' + str(max_enc_steps)]\n",
    "\n",
    "generated_path = 'log/myexperiment/decode_test_4000maxenc_4beam_35mindec_100maxdec_ckpt-238410/'\n",
    "max_len = 250\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(string):\n",
    "    return ' '.join([stemmer.stem(word.decode('utf8')) for word in string.lower().split() if not word in stopwords])\n",
    "    \n",
    "def write_to_file(article, abstract, rel, writer):\n",
    "    abstract = '<s> '+' '.join(abstract)+' </s>'\n",
    "    #abstract = abstract.encode('utf8', 'ignore')\n",
    "    #rel = rel.encode('utf8', 'ignore')\n",
    "    #article = article.encode('utf8', 'ignore')\n",
    "    tf_example = example_pb2.Example()\n",
    "    tf_example.features.feature['abstract'].bytes_list.value.extend([bytes(abstract)])\n",
    "    tf_example.features.feature['relevancy'].bytes_list.value.extend([bytes(rel)])\n",
    "    tf_example.features.feature['article'].bytes_list.value.extend([bytes(article)])\n",
    "    tf_example_str = tf_example.SerializeToString()\n",
    "    str_len = len(tf_example_str)\n",
    "    writer.write(struct.pack('q', str_len))\n",
    "    writer.write(struct.pack('%ds' % str_len, tf_example_str))\n",
    "\n",
    "\n",
    "def duck_iterator(i):\n",
    "    duc_folder = 'duc0' + str(i) + 'tokenized/'\n",
    "    for topic in os.listdir(duc_folder + 'testdata/docs/'):\n",
    "        topic_folder = duc_folder + 'testdata/docs/' + topic\n",
    "        if not os.path.isdir(topic_folder):\n",
    "            continue\n",
    "        query = ' '.join(open(duc_folder + 'queries/' + topic).readlines())\n",
    "        model_files = glob(duc_folder + 'models/' + topic[:-1].upper() + '.*')\n",
    "\n",
    "        topic_texts = [' '.join(open(topic_folder + '/' + file).readlines()).replace('\\n', '') for file in\n",
    "                       os.listdir(topic_folder)]\n",
    "\n",
    "        abstracts = [' '.join(open(f).readlines()) for f in model_files]\n",
    "        yield topic_texts, abstracts, query\n",
    "\n",
    "\n",
    "def count_score(sent, ref):\n",
    "    ref = pp(ref).split()\n",
    "    sent = ' '.join(pp(w) for w in sent.lower().split() if not w in stopwords)\n",
    "    return sum([1. if w in ref else 0. for w in sent.split()])\n",
    "\n",
    "\n",
    "def get_tfidf_score_func(magic = 1):\n",
    "    corpus = []\n",
    "    for i in range(5, 8):\n",
    "        for topic_texts, _, _ in duck_iterator(i):\n",
    "            corpus += [pp(t) for t in topic_texts]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit_transform(corpus)\n",
    "\n",
    "    def tfidf_score_func(sent, ref):\n",
    "        ref = [pp(s) for s in ref.split(' . ')]\n",
    "        sent = pp(sent)\n",
    "        v1 = vectorizer.transform([sent])\n",
    "        v2s = [vectorizer.transform([r]) for r in ref]\n",
    "        return max([cosine_similarity(v1, v2)[0][0] for v2 in v2s])\n",
    "    return tfidf_score_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_score = get_tfidf_score_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summary:\n",
    "    def __init__(self, texts, abstracts, query):\n",
    "        \n",
    "        #texts = sorted([(tfidf_score(query, text), text) for text in texts], reverse=True)\n",
    "        texts = sorted([(tfidf_score(text, ' '.join(abstracts)), text) for text in texts], reverse=True)\n",
    "\n",
    "        texts = [text[1] for text in texts]\n",
    "        self.texts = texts\n",
    "        self.abstracts = abstracts\n",
    "        self.query = query\n",
    "        self.summary = []\n",
    "        self.words = set()\n",
    "        self.length = 0\n",
    "\n",
    "    def most_similar(self, sent, text):\n",
    "        return max([(count_score(s, sent), s) for s in text])[1]\n",
    "\n",
    "    def add_sum(self, summ):\n",
    "        text = self.texts.pop(0).split(' . ')\n",
    "        if len(self.texts) == 0: return True\n",
    "        found_sents = []\n",
    "        for sent in summ:\n",
    "            ms = self.most_similar(sent, text)\n",
    "            if ms in found_sents:\n",
    "                continue\n",
    "            found_sents.append(sent)\n",
    "            splitted = pp(sent).split()\n",
    "            length = len(splitted) \n",
    "            splitted = set(splitted)       \n",
    "            if self.length+length > max_len: return True\n",
    "            if len(splitted - self.words) < int(len(splitted)*0.5): return False\n",
    "            self.words |= splitted     \n",
    "            self.summary.append(sent)\n",
    "            self.length +=length\n",
    "        return False\n",
    "\n",
    "    def get(self):\n",
    "        text = self.texts[0]\n",
    "        sents = text.split(' . ')\n",
    "        #score_per_sent = [(count_score(sent, self.query), sent) for sent in sents]\n",
    "        score_per_sent = [(count_score(sent, ' '.join(self.abstracts)), sent) for sent in sents]\n",
    "\n",
    "        scores = []\n",
    "        for score, sent in score_per_sent:\n",
    "            scores += [score] * (len(sent.split()) + 1)\n",
    "        scores = str(scores[:-1])\n",
    "        return text, 'a', scores\n",
    "\n",
    "def get_summaries(path):\n",
    "    path = path+'decoded/'\n",
    "    out = {}\n",
    "    for file_name in os.listdir(path):\n",
    "        index = int(file_name.split('_')[0])\n",
    "        out[index] = open(path+file_name).readlines()\n",
    "    return out\n",
    "\n",
    "def rouge_eval(ref_dir, dec_dir):\n",
    "    \"\"\"Evaluate the files in ref_dir and dec_dir with pyrouge, returning results_dict\"\"\"\n",
    "    r = pyrouge.Rouge155()\n",
    "    r.model_filename_pattern = '#ID#_reference_(\\d+).txt'\n",
    "    r.system_filename_pattern = '(\\d+)_decoded.txt'\n",
    "    r.model_dir = ref_dir\n",
    "    r.system_dir = dec_dir\n",
    "    return r.convert_and_evaluate()\n",
    "\n",
    "def evaluate(summaries):\n",
    "    for path in ['eval/ref', 'eval/dec']:\n",
    "        if os.path.exists(path): shutil.rmtree(path, True)\n",
    "        os.mkdir(path)\n",
    "    for i, summ in enumerate(summaries):\n",
    "        for j,abs in enumerate(summ.abstracts):\n",
    "            with open('eval/ref/'+str(i)+'_reference_'+str(j)+'.txt', 'w') as f:\n",
    "                f.write(abs)\n",
    "        with open('eval/dec/'+str(i)+'_decoded.txt', 'w') as f:\n",
    "            f.write(' '.join(summ.summary))\n",
    "    print rouge_eval('eval/ref/', 'eval/dec/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-12 14:22:24,517 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2019-02-12 14:22:24,521 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpdq_BAI/system and model files to /tmp/tmpdq_BAI/model.\n",
      "2019-02-12 14:22:24,522 [MainThread  ] [INFO ]  Processing files in eval/dec/.\n",
      "2019-02-12 14:22:24,523 [MainThread  ] [INFO ]  Processing 0_decoded.txt.\n",
      "2019-02-12 14:22:24,525 [MainThread  ] [INFO ]  Processing 1_decoded.txt.\n",
      "2019-02-12 14:22:24,527 [MainThread  ] [INFO ]  Processing 2_decoded.txt.\n",
      "2019-02-12 14:22:24,530 [MainThread  ] [INFO ]  Processing 3_decoded.txt.\n",
      "2019-02-12 14:22:24,532 [MainThread  ] [INFO ]  Processing 4_decoded.txt.\n",
      "2019-02-12 14:22:24,534 [MainThread  ] [INFO ]  Processing 5_decoded.txt.\n",
      "2019-02-12 14:22:24,537 [MainThread  ] [INFO ]  Processing 6_decoded.txt.\n",
      "2019-02-12 14:22:24,539 [MainThread  ] [INFO ]  Processing 7_decoded.txt.\n",
      "2019-02-12 14:22:24,541 [MainThread  ] [INFO ]  Processing 8_decoded.txt.\n",
      "2019-02-12 14:22:24,543 [MainThread  ] [INFO ]  Processing 9_decoded.txt.\n",
      "2019-02-12 14:22:24,545 [MainThread  ] [INFO ]  Processing 10_decoded.txt.\n",
      "2019-02-12 14:22:24,547 [MainThread  ] [INFO ]  Processing 11_decoded.txt.\n",
      "2019-02-12 14:22:24,549 [MainThread  ] [INFO ]  Processing 12_decoded.txt.\n",
      "2019-02-12 14:22:24,552 [MainThread  ] [INFO ]  Processing 13_decoded.txt.\n",
      "2019-02-12 14:22:24,554 [MainThread  ] [INFO ]  Processing 14_decoded.txt.\n",
      "2019-02-12 14:22:24,556 [MainThread  ] [INFO ]  Processing 15_decoded.txt.\n",
      "2019-02-12 14:22:24,558 [MainThread  ] [INFO ]  Processing 16_decoded.txt.\n",
      "2019-02-12 14:22:24,560 [MainThread  ] [INFO ]  Processing 17_decoded.txt.\n",
      "2019-02-12 14:22:24,562 [MainThread  ] [INFO ]  Processing 18_decoded.txt.\n",
      "2019-02-12 14:22:24,564 [MainThread  ] [INFO ]  Processing 19_decoded.txt.\n",
      "2019-02-12 14:22:24,567 [MainThread  ] [INFO ]  Processing 20_decoded.txt.\n",
      "2019-02-12 14:22:24,569 [MainThread  ] [INFO ]  Processing 21_decoded.txt.\n",
      "2019-02-12 14:22:24,571 [MainThread  ] [INFO ]  Processing 22_decoded.txt.\n",
      "2019-02-12 14:22:24,573 [MainThread  ] [INFO ]  Processing 23_decoded.txt.\n",
      "2019-02-12 14:22:24,575 [MainThread  ] [INFO ]  Processing 24_decoded.txt.\n",
      "2019-02-12 14:22:24,577 [MainThread  ] [INFO ]  Processing 25_decoded.txt.\n",
      "2019-02-12 14:22:24,579 [MainThread  ] [INFO ]  Processing 26_decoded.txt.\n",
      "2019-02-12 14:22:24,582 [MainThread  ] [INFO ]  Processing 27_decoded.txt.\n",
      "2019-02-12 14:22:24,584 [MainThread  ] [INFO ]  Processing 28_decoded.txt.\n",
      "2019-02-12 14:22:24,586 [MainThread  ] [INFO ]  Processing 29_decoded.txt.\n",
      "2019-02-12 14:22:24,588 [MainThread  ] [INFO ]  Processing 30_decoded.txt.\n",
      "2019-02-12 14:22:24,590 [MainThread  ] [INFO ]  Processing 31_decoded.txt.\n",
      "2019-02-12 14:22:24,592 [MainThread  ] [INFO ]  Processing 32_decoded.txt.\n",
      "2019-02-12 14:22:24,595 [MainThread  ] [INFO ]  Processing 33_decoded.txt.\n",
      "2019-02-12 14:22:24,597 [MainThread  ] [INFO ]  Processing 34_decoded.txt.\n",
      "2019-02-12 14:22:24,599 [MainThread  ] [INFO ]  Processing 35_decoded.txt.\n",
      "2019-02-12 14:22:24,601 [MainThread  ] [INFO ]  Processing 36_decoded.txt.\n",
      "2019-02-12 14:22:24,603 [MainThread  ] [INFO ]  Processing 37_decoded.txt.\n",
      "2019-02-12 14:22:24,605 [MainThread  ] [INFO ]  Processing 38_decoded.txt.\n",
      "2019-02-12 14:22:24,607 [MainThread  ] [INFO ]  Processing 39_decoded.txt.\n",
      "2019-02-12 14:22:24,610 [MainThread  ] [INFO ]  Processing 40_decoded.txt.\n",
      "2019-02-12 14:22:24,612 [MainThread  ] [INFO ]  Processing 41_decoded.txt.\n",
      "2019-02-12 14:22:24,614 [MainThread  ] [INFO ]  Processing 42_decoded.txt.\n",
      "2019-02-12 14:22:24,616 [MainThread  ] [INFO ]  Processing 43_decoded.txt.\n",
      "2019-02-12 14:22:24,618 [MainThread  ] [INFO ]  Processing 44_decoded.txt.\n",
      "2019-02-12 14:22:24,620 [MainThread  ] [INFO ]  Processing 45_decoded.txt.\n",
      "2019-02-12 14:22:24,623 [MainThread  ] [INFO ]  Processing 46_decoded.txt.\n",
      "2019-02-12 14:22:24,625 [MainThread  ] [INFO ]  Processing 47_decoded.txt.\n",
      "2019-02-12 14:22:24,627 [MainThread  ] [INFO ]  Processing 48_decoded.txt.\n",
      "2019-02-12 14:22:24,629 [MainThread  ] [INFO ]  Processing 49_decoded.txt.\n",
      "2019-02-12 14:22:24,631 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdq_BAI/system.\n",
      "2019-02-12 14:22:24,632 [MainThread  ] [INFO ]  Processing files in eval/ref/.\n",
      "2019-02-12 14:22:24,634 [MainThread  ] [INFO ]  Processing 0_reference_0.txt.\n",
      "2019-02-12 14:22:24,636 [MainThread  ] [INFO ]  Processing 0_reference_1.txt.\n",
      "2019-02-12 14:22:24,638 [MainThread  ] [INFO ]  Processing 0_reference_2.txt.\n",
      "2019-02-12 14:22:24,640 [MainThread  ] [INFO ]  Processing 0_reference_3.txt.\n",
      "2019-02-12 14:22:24,642 [MainThread  ] [INFO ]  Processing 1_reference_0.txt.\n",
      "2019-02-12 14:22:24,644 [MainThread  ] [INFO ]  Processing 1_reference_1.txt.\n",
      "2019-02-12 14:22:24,646 [MainThread  ] [INFO ]  Processing 1_reference_2.txt.\n",
      "2019-02-12 14:22:24,649 [MainThread  ] [INFO ]  Processing 1_reference_3.txt.\n",
      "2019-02-12 14:22:24,651 [MainThread  ] [INFO ]  Processing 2_reference_0.txt.\n",
      "2019-02-12 14:22:24,653 [MainThread  ] [INFO ]  Processing 2_reference_1.txt.\n",
      "2019-02-12 14:22:24,655 [MainThread  ] [INFO ]  Processing 2_reference_2.txt.\n",
      "2019-02-12 14:22:24,657 [MainThread  ] [INFO ]  Processing 2_reference_3.txt.\n",
      "2019-02-12 14:22:24,659 [MainThread  ] [INFO ]  Processing 3_reference_0.txt.\n",
      "2019-02-12 14:22:24,661 [MainThread  ] [INFO ]  Processing 3_reference_1.txt.\n",
      "2019-02-12 14:22:24,664 [MainThread  ] [INFO ]  Processing 3_reference_2.txt.\n",
      "2019-02-12 14:22:24,666 [MainThread  ] [INFO ]  Processing 3_reference_3.txt.\n",
      "2019-02-12 14:22:24,668 [MainThread  ] [INFO ]  Processing 4_reference_0.txt.\n",
      "2019-02-12 14:22:24,670 [MainThread  ] [INFO ]  Processing 4_reference_1.txt.\n",
      "2019-02-12 14:22:24,672 [MainThread  ] [INFO ]  Processing 4_reference_2.txt.\n",
      "2019-02-12 14:22:24,674 [MainThread  ] [INFO ]  Processing 4_reference_3.txt.\n",
      "2019-02-12 14:22:24,677 [MainThread  ] [INFO ]  Processing 5_reference_0.txt.\n",
      "2019-02-12 14:22:24,679 [MainThread  ] [INFO ]  Processing 5_reference_1.txt.\n",
      "2019-02-12 14:22:24,681 [MainThread  ] [INFO ]  Processing 5_reference_2.txt.\n",
      "2019-02-12 14:22:24,683 [MainThread  ] [INFO ]  Processing 5_reference_3.txt.\n",
      "2019-02-12 14:22:24,685 [MainThread  ] [INFO ]  Processing 6_reference_0.txt.\n",
      "2019-02-12 14:22:24,688 [MainThread  ] [INFO ]  Processing 6_reference_1.txt.\n",
      "2019-02-12 14:22:24,690 [MainThread  ] [INFO ]  Processing 6_reference_2.txt.\n",
      "2019-02-12 14:22:24,692 [MainThread  ] [INFO ]  Processing 6_reference_3.txt.\n",
      "2019-02-12 14:22:24,694 [MainThread  ] [INFO ]  Processing 7_reference_0.txt.\n",
      "2019-02-12 14:22:24,696 [MainThread  ] [INFO ]  Processing 7_reference_1.txt.\n",
      "2019-02-12 14:22:24,698 [MainThread  ] [INFO ]  Processing 7_reference_2.txt.\n",
      "2019-02-12 14:22:24,700 [MainThread  ] [INFO ]  Processing 7_reference_3.txt.\n",
      "2019-02-12 14:22:24,702 [MainThread  ] [INFO ]  Processing 8_reference_0.txt.\n",
      "2019-02-12 14:22:24,705 [MainThread  ] [INFO ]  Processing 8_reference_1.txt.\n",
      "2019-02-12 14:22:24,707 [MainThread  ] [INFO ]  Processing 8_reference_2.txt.\n",
      "2019-02-12 14:22:24,709 [MainThread  ] [INFO ]  Processing 8_reference_3.txt.\n",
      "2019-02-12 14:22:24,711 [MainThread  ] [INFO ]  Processing 9_reference_0.txt.\n",
      "2019-02-12 14:22:24,713 [MainThread  ] [INFO ]  Processing 9_reference_1.txt.\n",
      "2019-02-12 14:22:24,715 [MainThread  ] [INFO ]  Processing 9_reference_2.txt.\n",
      "2019-02-12 14:22:24,717 [MainThread  ] [INFO ]  Processing 9_reference_3.txt.\n",
      "2019-02-12 14:22:24,719 [MainThread  ] [INFO ]  Processing 10_reference_0.txt.\n",
      "2019-02-12 14:22:24,721 [MainThread  ] [INFO ]  Processing 10_reference_1.txt.\n",
      "2019-02-12 14:22:24,723 [MainThread  ] [INFO ]  Processing 10_reference_2.txt.\n",
      "2019-02-12 14:22:24,726 [MainThread  ] [INFO ]  Processing 10_reference_3.txt.\n",
      "2019-02-12 14:22:24,728 [MainThread  ] [INFO ]  Processing 11_reference_0.txt.\n",
      "2019-02-12 14:22:24,730 [MainThread  ] [INFO ]  Processing 11_reference_1.txt.\n",
      "2019-02-12 14:22:24,732 [MainThread  ] [INFO ]  Processing 11_reference_2.txt.\n",
      "2019-02-12 14:22:24,734 [MainThread  ] [INFO ]  Processing 11_reference_3.txt.\n",
      "2019-02-12 14:22:24,737 [MainThread  ] [INFO ]  Processing 12_reference_0.txt.\n",
      "2019-02-12 14:22:24,739 [MainThread  ] [INFO ]  Processing 12_reference_1.txt.\n",
      "2019-02-12 14:22:24,741 [MainThread  ] [INFO ]  Processing 12_reference_2.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-12 14:22:24,743 [MainThread  ] [INFO ]  Processing 12_reference_3.txt.\n",
      "2019-02-12 14:22:24,745 [MainThread  ] [INFO ]  Processing 13_reference_0.txt.\n",
      "2019-02-12 14:22:24,748 [MainThread  ] [INFO ]  Processing 13_reference_1.txt.\n",
      "2019-02-12 14:22:24,750 [MainThread  ] [INFO ]  Processing 13_reference_2.txt.\n",
      "2019-02-12 14:22:24,752 [MainThread  ] [INFO ]  Processing 13_reference_3.txt.\n",
      "2019-02-12 14:22:24,754 [MainThread  ] [INFO ]  Processing 14_reference_0.txt.\n",
      "2019-02-12 14:22:24,756 [MainThread  ] [INFO ]  Processing 14_reference_1.txt.\n",
      "2019-02-12 14:22:24,758 [MainThread  ] [INFO ]  Processing 14_reference_2.txt.\n",
      "2019-02-12 14:22:24,760 [MainThread  ] [INFO ]  Processing 14_reference_3.txt.\n",
      "2019-02-12 14:22:24,762 [MainThread  ] [INFO ]  Processing 15_reference_0.txt.\n",
      "2019-02-12 14:22:24,765 [MainThread  ] [INFO ]  Processing 15_reference_1.txt.\n",
      "2019-02-12 14:22:24,767 [MainThread  ] [INFO ]  Processing 15_reference_2.txt.\n",
      "2019-02-12 14:22:24,769 [MainThread  ] [INFO ]  Processing 15_reference_3.txt.\n",
      "2019-02-12 14:22:24,771 [MainThread  ] [INFO ]  Processing 16_reference_0.txt.\n",
      "2019-02-12 14:22:24,774 [MainThread  ] [INFO ]  Processing 16_reference_1.txt.\n",
      "2019-02-12 14:22:24,776 [MainThread  ] [INFO ]  Processing 16_reference_2.txt.\n",
      "2019-02-12 14:22:24,778 [MainThread  ] [INFO ]  Processing 16_reference_3.txt.\n",
      "2019-02-12 14:22:24,780 [MainThread  ] [INFO ]  Processing 17_reference_0.txt.\n",
      "2019-02-12 14:22:24,782 [MainThread  ] [INFO ]  Processing 17_reference_1.txt.\n",
      "2019-02-12 14:22:24,784 [MainThread  ] [INFO ]  Processing 17_reference_2.txt.\n",
      "2019-02-12 14:22:24,787 [MainThread  ] [INFO ]  Processing 17_reference_3.txt.\n",
      "2019-02-12 14:22:24,789 [MainThread  ] [INFO ]  Processing 18_reference_0.txt.\n",
      "2019-02-12 14:22:24,791 [MainThread  ] [INFO ]  Processing 18_reference_1.txt.\n",
      "2019-02-12 14:22:24,794 [MainThread  ] [INFO ]  Processing 18_reference_2.txt.\n",
      "2019-02-12 14:22:24,796 [MainThread  ] [INFO ]  Processing 18_reference_3.txt.\n",
      "2019-02-12 14:22:24,798 [MainThread  ] [INFO ]  Processing 19_reference_0.txt.\n",
      "2019-02-12 14:22:24,800 [MainThread  ] [INFO ]  Processing 19_reference_1.txt.\n",
      "2019-02-12 14:22:24,802 [MainThread  ] [INFO ]  Processing 19_reference_2.txt.\n",
      "2019-02-12 14:22:24,804 [MainThread  ] [INFO ]  Processing 19_reference_3.txt.\n",
      "2019-02-12 14:22:24,807 [MainThread  ] [INFO ]  Processing 20_reference_0.txt.\n",
      "2019-02-12 14:22:24,809 [MainThread  ] [INFO ]  Processing 20_reference_1.txt.\n",
      "2019-02-12 14:22:24,811 [MainThread  ] [INFO ]  Processing 20_reference_2.txt.\n",
      "2019-02-12 14:22:24,813 [MainThread  ] [INFO ]  Processing 20_reference_3.txt.\n",
      "2019-02-12 14:22:24,816 [MainThread  ] [INFO ]  Processing 21_reference_0.txt.\n",
      "2019-02-12 14:22:24,818 [MainThread  ] [INFO ]  Processing 21_reference_1.txt.\n",
      "2019-02-12 14:22:24,820 [MainThread  ] [INFO ]  Processing 21_reference_2.txt.\n",
      "2019-02-12 14:22:24,822 [MainThread  ] [INFO ]  Processing 21_reference_3.txt.\n",
      "2019-02-12 14:22:24,825 [MainThread  ] [INFO ]  Processing 22_reference_0.txt.\n",
      "2019-02-12 14:22:24,827 [MainThread  ] [INFO ]  Processing 22_reference_1.txt.\n",
      "2019-02-12 14:22:24,829 [MainThread  ] [INFO ]  Processing 22_reference_2.txt.\n",
      "2019-02-12 14:22:24,831 [MainThread  ] [INFO ]  Processing 22_reference_3.txt.\n",
      "2019-02-12 14:22:24,834 [MainThread  ] [INFO ]  Processing 23_reference_0.txt.\n",
      "2019-02-12 14:22:24,836 [MainThread  ] [INFO ]  Processing 23_reference_1.txt.\n",
      "2019-02-12 14:22:24,838 [MainThread  ] [INFO ]  Processing 23_reference_2.txt.\n",
      "2019-02-12 14:22:24,840 [MainThread  ] [INFO ]  Processing 23_reference_3.txt.\n",
      "2019-02-12 14:22:24,842 [MainThread  ] [INFO ]  Processing 24_reference_0.txt.\n",
      "2019-02-12 14:22:24,845 [MainThread  ] [INFO ]  Processing 24_reference_1.txt.\n",
      "2019-02-12 14:22:24,847 [MainThread  ] [INFO ]  Processing 24_reference_2.txt.\n",
      "2019-02-12 14:22:24,849 [MainThread  ] [INFO ]  Processing 24_reference_3.txt.\n",
      "2019-02-12 14:22:24,851 [MainThread  ] [INFO ]  Processing 25_reference_0.txt.\n",
      "2019-02-12 14:22:24,853 [MainThread  ] [INFO ]  Processing 25_reference_1.txt.\n",
      "2019-02-12 14:22:24,855 [MainThread  ] [INFO ]  Processing 25_reference_2.txt.\n",
      "2019-02-12 14:22:24,858 [MainThread  ] [INFO ]  Processing 25_reference_3.txt.\n",
      "2019-02-12 14:22:24,860 [MainThread  ] [INFO ]  Processing 26_reference_0.txt.\n",
      "2019-02-12 14:22:24,862 [MainThread  ] [INFO ]  Processing 26_reference_1.txt.\n",
      "2019-02-12 14:22:24,865 [MainThread  ] [INFO ]  Processing 26_reference_2.txt.\n",
      "2019-02-12 14:22:24,867 [MainThread  ] [INFO ]  Processing 26_reference_3.txt.\n",
      "2019-02-12 14:22:24,869 [MainThread  ] [INFO ]  Processing 27_reference_0.txt.\n",
      "2019-02-12 14:22:24,871 [MainThread  ] [INFO ]  Processing 27_reference_1.txt.\n",
      "2019-02-12 14:22:24,873 [MainThread  ] [INFO ]  Processing 27_reference_2.txt.\n",
      "2019-02-12 14:22:24,876 [MainThread  ] [INFO ]  Processing 27_reference_3.txt.\n",
      "2019-02-12 14:22:24,878 [MainThread  ] [INFO ]  Processing 28_reference_0.txt.\n",
      "2019-02-12 14:22:24,880 [MainThread  ] [INFO ]  Processing 28_reference_1.txt.\n",
      "2019-02-12 14:22:24,882 [MainThread  ] [INFO ]  Processing 28_reference_2.txt.\n",
      "2019-02-12 14:22:24,884 [MainThread  ] [INFO ]  Processing 28_reference_3.txt.\n",
      "2019-02-12 14:22:24,886 [MainThread  ] [INFO ]  Processing 29_reference_0.txt.\n",
      "2019-02-12 14:22:24,888 [MainThread  ] [INFO ]  Processing 29_reference_1.txt.\n",
      "2019-02-12 14:22:24,891 [MainThread  ] [INFO ]  Processing 29_reference_2.txt.\n",
      "2019-02-12 14:22:24,893 [MainThread  ] [INFO ]  Processing 29_reference_3.txt.\n",
      "2019-02-12 14:22:24,895 [MainThread  ] [INFO ]  Processing 30_reference_0.txt.\n",
      "2019-02-12 14:22:24,897 [MainThread  ] [INFO ]  Processing 30_reference_1.txt.\n",
      "2019-02-12 14:22:24,899 [MainThread  ] [INFO ]  Processing 30_reference_2.txt.\n",
      "2019-02-12 14:22:24,902 [MainThread  ] [INFO ]  Processing 30_reference_3.txt.\n",
      "2019-02-12 14:22:24,904 [MainThread  ] [INFO ]  Processing 31_reference_0.txt.\n",
      "2019-02-12 14:22:24,906 [MainThread  ] [INFO ]  Processing 31_reference_1.txt.\n",
      "2019-02-12 14:22:24,908 [MainThread  ] [INFO ]  Processing 31_reference_2.txt.\n",
      "2019-02-12 14:22:24,910 [MainThread  ] [INFO ]  Processing 31_reference_3.txt.\n",
      "2019-02-12 14:22:24,912 [MainThread  ] [INFO ]  Processing 32_reference_0.txt.\n",
      "2019-02-12 14:22:24,915 [MainThread  ] [INFO ]  Processing 32_reference_1.txt.\n",
      "2019-02-12 14:22:24,917 [MainThread  ] [INFO ]  Processing 32_reference_2.txt.\n",
      "2019-02-12 14:22:24,919 [MainThread  ] [INFO ]  Processing 32_reference_3.txt.\n",
      "2019-02-12 14:22:24,922 [MainThread  ] [INFO ]  Processing 33_reference_0.txt.\n",
      "2019-02-12 14:22:24,924 [MainThread  ] [INFO ]  Processing 33_reference_1.txt.\n",
      "2019-02-12 14:22:24,926 [MainThread  ] [INFO ]  Processing 33_reference_2.txt.\n",
      "2019-02-12 14:22:24,928 [MainThread  ] [INFO ]  Processing 33_reference_3.txt.\n",
      "2019-02-12 14:22:24,930 [MainThread  ] [INFO ]  Processing 34_reference_0.txt.\n",
      "2019-02-12 14:22:24,933 [MainThread  ] [INFO ]  Processing 34_reference_1.txt.\n",
      "2019-02-12 14:22:24,935 [MainThread  ] [INFO ]  Processing 34_reference_2.txt.\n",
      "2019-02-12 14:22:24,937 [MainThread  ] [INFO ]  Processing 34_reference_3.txt.\n",
      "2019-02-12 14:22:24,939 [MainThread  ] [INFO ]  Processing 35_reference_0.txt.\n",
      "2019-02-12 14:22:24,942 [MainThread  ] [INFO ]  Processing 35_reference_1.txt.\n",
      "2019-02-12 14:22:24,944 [MainThread  ] [INFO ]  Processing 35_reference_2.txt.\n",
      "2019-02-12 14:22:24,946 [MainThread  ] [INFO ]  Processing 35_reference_3.txt.\n",
      "2019-02-12 14:22:24,948 [MainThread  ] [INFO ]  Processing 36_reference_0.txt.\n",
      "2019-02-12 14:22:24,950 [MainThread  ] [INFO ]  Processing 36_reference_1.txt.\n",
      "2019-02-12 14:22:24,953 [MainThread  ] [INFO ]  Processing 36_reference_2.txt.\n",
      "2019-02-12 14:22:24,955 [MainThread  ] [INFO ]  Processing 36_reference_3.txt.\n",
      "2019-02-12 14:22:24,957 [MainThread  ] [INFO ]  Processing 37_reference_0.txt.\n",
      "2019-02-12 14:22:24,959 [MainThread  ] [INFO ]  Processing 37_reference_1.txt.\n",
      "2019-02-12 14:22:24,961 [MainThread  ] [INFO ]  Processing 37_reference_2.txt.\n",
      "2019-02-12 14:22:24,963 [MainThread  ] [INFO ]  Processing 37_reference_3.txt.\n",
      "2019-02-12 14:22:24,966 [MainThread  ] [INFO ]  Processing 38_reference_0.txt.\n",
      "2019-02-12 14:22:24,969 [MainThread  ] [INFO ]  Processing 38_reference_1.txt.\n",
      "2019-02-12 14:22:24,971 [MainThread  ] [INFO ]  Processing 38_reference_2.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-12 14:22:24,973 [MainThread  ] [INFO ]  Processing 38_reference_3.txt.\n",
      "2019-02-12 14:22:24,975 [MainThread  ] [INFO ]  Processing 39_reference_0.txt.\n",
      "2019-02-12 14:22:24,978 [MainThread  ] [INFO ]  Processing 39_reference_1.txt.\n",
      "2019-02-12 14:22:24,980 [MainThread  ] [INFO ]  Processing 39_reference_2.txt.\n",
      "2019-02-12 14:22:24,982 [MainThread  ] [INFO ]  Processing 39_reference_3.txt.\n",
      "2019-02-12 14:22:24,984 [MainThread  ] [INFO ]  Processing 40_reference_0.txt.\n",
      "2019-02-12 14:22:24,987 [MainThread  ] [INFO ]  Processing 40_reference_1.txt.\n",
      "2019-02-12 14:22:24,990 [MainThread  ] [INFO ]  Processing 40_reference_2.txt.\n",
      "2019-02-12 14:22:24,992 [MainThread  ] [INFO ]  Processing 40_reference_3.txt.\n",
      "2019-02-12 14:22:24,994 [MainThread  ] [INFO ]  Processing 41_reference_0.txt.\n",
      "2019-02-12 14:22:24,996 [MainThread  ] [INFO ]  Processing 41_reference_1.txt.\n",
      "2019-02-12 14:22:24,998 [MainThread  ] [INFO ]  Processing 41_reference_2.txt.\n",
      "2019-02-12 14:22:25,001 [MainThread  ] [INFO ]  Processing 41_reference_3.txt.\n",
      "2019-02-12 14:22:25,003 [MainThread  ] [INFO ]  Processing 42_reference_0.txt.\n",
      "2019-02-12 14:22:25,005 [MainThread  ] [INFO ]  Processing 42_reference_1.txt.\n",
      "2019-02-12 14:22:25,007 [MainThread  ] [INFO ]  Processing 42_reference_2.txt.\n",
      "2019-02-12 14:22:25,009 [MainThread  ] [INFO ]  Processing 42_reference_3.txt.\n",
      "2019-02-12 14:22:25,011 [MainThread  ] [INFO ]  Processing 43_reference_0.txt.\n",
      "2019-02-12 14:22:25,013 [MainThread  ] [INFO ]  Processing 43_reference_1.txt.\n",
      "2019-02-12 14:22:25,016 [MainThread  ] [INFO ]  Processing 43_reference_2.txt.\n",
      "2019-02-12 14:22:25,018 [MainThread  ] [INFO ]  Processing 43_reference_3.txt.\n",
      "2019-02-12 14:22:25,020 [MainThread  ] [INFO ]  Processing 44_reference_0.txt.\n",
      "2019-02-12 14:22:25,022 [MainThread  ] [INFO ]  Processing 44_reference_1.txt.\n",
      "2019-02-12 14:22:25,025 [MainThread  ] [INFO ]  Processing 44_reference_2.txt.\n",
      "2019-02-12 14:22:25,027 [MainThread  ] [INFO ]  Processing 44_reference_3.txt.\n",
      "2019-02-12 14:22:25,029 [MainThread  ] [INFO ]  Processing 45_reference_0.txt.\n",
      "2019-02-12 14:22:25,031 [MainThread  ] [INFO ]  Processing 45_reference_1.txt.\n",
      "2019-02-12 14:22:25,033 [MainThread  ] [INFO ]  Processing 45_reference_2.txt.\n",
      "2019-02-12 14:22:25,036 [MainThread  ] [INFO ]  Processing 45_reference_3.txt.\n",
      "2019-02-12 14:22:25,038 [MainThread  ] [INFO ]  Processing 46_reference_0.txt.\n",
      "2019-02-12 14:22:25,040 [MainThread  ] [INFO ]  Processing 46_reference_1.txt.\n",
      "2019-02-12 14:22:25,042 [MainThread  ] [INFO ]  Processing 46_reference_2.txt.\n",
      "2019-02-12 14:22:25,044 [MainThread  ] [INFO ]  Processing 46_reference_3.txt.\n",
      "2019-02-12 14:22:25,046 [MainThread  ] [INFO ]  Processing 47_reference_0.txt.\n",
      "2019-02-12 14:22:25,049 [MainThread  ] [INFO ]  Processing 47_reference_1.txt.\n",
      "2019-02-12 14:22:25,051 [MainThread  ] [INFO ]  Processing 47_reference_2.txt.\n",
      "2019-02-12 14:22:25,053 [MainThread  ] [INFO ]  Processing 47_reference_3.txt.\n",
      "2019-02-12 14:22:25,055 [MainThread  ] [INFO ]  Processing 48_reference_0.txt.\n",
      "2019-02-12 14:22:25,057 [MainThread  ] [INFO ]  Processing 48_reference_1.txt.\n",
      "2019-02-12 14:22:25,059 [MainThread  ] [INFO ]  Processing 48_reference_2.txt.\n",
      "2019-02-12 14:22:25,061 [MainThread  ] [INFO ]  Processing 48_reference_3.txt.\n",
      "2019-02-12 14:22:25,063 [MainThread  ] [INFO ]  Processing 49_reference_0.txt.\n",
      "2019-02-12 14:22:25,066 [MainThread  ] [INFO ]  Processing 49_reference_1.txt.\n",
      "2019-02-12 14:22:25,068 [MainThread  ] [INFO ]  Processing 49_reference_2.txt.\n",
      "2019-02-12 14:22:25,070 [MainThread  ] [INFO ]  Processing 49_reference_3.txt.\n",
      "2019-02-12 14:22:25,072 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdq_BAI/model.\n",
      "2019-02-12 14:22:25,090 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpDDgisg/rouge_conf.xml\n",
      "2019-02-12 14:22:25,091 [MainThread  ] [INFO ]  Running ROUGE with command /home/stephaneg/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/stephaneg/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpDDgisg/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.46971 (95%-conf.int. 0.45550 - 0.48423)\n",
      "1 ROUGE-1 Average_P: 0.37811 (95%-conf.int. 0.36836 - 0.38713)\n",
      "1 ROUGE-1 Average_F: 0.41845 (95%-conf.int. 0.40787 - 0.42896)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.11246 (95%-conf.int. 0.10290 - 0.12176)\n",
      "1 ROUGE-2 Average_P: 0.09037 (95%-conf.int. 0.08301 - 0.09750)\n",
      "1 ROUGE-2 Average_F: 0.10009 (95%-conf.int. 0.09167 - 0.10826)\n",
      "---------------------------------------------\n",
      "1 ROUGE-3 Average_R: 0.04194 (95%-conf.int. 0.03613 - 0.04794)\n",
      "1 ROUGE-3 Average_P: 0.03363 (95%-conf.int. 0.02929 - 0.03826)\n",
      "1 ROUGE-3 Average_F: 0.03729 (95%-conf.int. 0.03235 - 0.04269)\n",
      "---------------------------------------------\n",
      "1 ROUGE-4 Average_R: 0.02303 (95%-conf.int. 0.01899 - 0.02759)\n",
      "1 ROUGE-4 Average_P: 0.01839 (95%-conf.int. 0.01521 - 0.02198)\n",
      "1 ROUGE-4 Average_F: 0.02042 (95%-conf.int. 0.01687 - 0.02440)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.43499 (95%-conf.int. 0.42212 - 0.44799)\n",
      "1 ROUGE-L Average_P: 0.35012 (95%-conf.int. 0.34065 - 0.35825)\n",
      "1 ROUGE-L Average_F: 0.38749 (95%-conf.int. 0.37751 - 0.39733)\n",
      "---------------------------------------------\n",
      "1 ROUGE-W-1.2 Average_R: 0.12665 (95%-conf.int. 0.12239 - 0.13082)\n",
      "1 ROUGE-W-1.2 Average_P: 0.18623 (95%-conf.int. 0.18133 - 0.19106)\n",
      "1 ROUGE-W-1.2 Average_F: 0.15058 (95%-conf.int. 0.14620 - 0.15513)\n",
      "---------------------------------------------\n",
      "1 ROUGE-S* Average_R: 0.20223 (95%-conf.int. 0.19097 - 0.21369)\n",
      "1 ROUGE-S* Average_P: 0.13067 (95%-conf.int. 0.12438 - 0.13646)\n",
      "1 ROUGE-S* Average_F: 0.15801 (95%-conf.int. 0.15065 - 0.16563)\n",
      "---------------------------------------------\n",
      "1 ROUGE-SU* Average_R: 0.20432 (95%-conf.int. 0.19302 - 0.21579)\n",
      "1 ROUGE-SU* Average_P: 0.13223 (95%-conf.int. 0.12595 - 0.13802)\n",
      "1 ROUGE-SU* Average_F: 0.15981 (95%-conf.int. 0.15245 - 0.16744)\n",
      "\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in [6]:\n",
    "    duc_num = i\n",
    "    done_summaries = []\n",
    "    summaries = [Summary(texts, abstracts, query) for texts, abstracts, query in duck_iterator(i)]\n",
    "    while summaries:\n",
    "        with open('test/temp_file', 'wb') as writer:\n",
    "            for summ in summaries:\n",
    "                article, abstract, scores = summ.get()\n",
    "                write_to_file(article, abstracts, scores, writer)\n",
    "        call(['rm', '-r', generated_path])     \n",
    "        call(cmd)\n",
    "        generated_summaries = get_summaries(generated_path)\n",
    "        should_remove = []\n",
    "        for i in range(len(summaries)):\n",
    "            if summaries[i].add_sum(generated_summaries[i]):\n",
    "                should_remove.append(i)\n",
    "        for i in should_remove[::-1]: \n",
    "            done_summaries.append(summaries.pop(i))\n",
    "    evaluate(done_summaries)\n",
    "    print duc_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
