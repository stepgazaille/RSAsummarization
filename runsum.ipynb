{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "from glob import glob\n",
    "from nltk.corpus import stopwords\n",
    "import os, struct\n",
    "from tensorflow.core.example import example_pb2\n",
    "import pyrouge\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 1\n",
    "duc_num = 5\n",
    "max_len = 250\n",
    "\n",
    "#cmd = '/root/miniconda2/bin/python ../pointer-generator-master/run_summarization.py --mode=decode --single_pass=1 --coverage=True --vocab_path=finished_files/vocab --log_root=log --exp_name=myexperiment --data_path=test/temp_file'\n",
    "#cmd = '/root/miniconda2/bin/python run_summarization.py --mode=decode --single_pass=1 --coverage=True --vocab_path=finished_files/vocab --log_root=log --exp_name=myexperiment --data_path=test/temp_file --max_enc_steps=4000'\n",
    "#cmd = cmd.split()\n",
    "#generated_path = '/gttp/pointer-generator-master/log/myexperiment/decode_test_4000maxenc_4beam_35mindec_120maxdec_ckpt-238410/'\n",
    "#generated_path = '/gttp/pointer-generator-tal/log/myexperiment/decode_test_4000maxenc_4beam_35mindec_100maxdec_ckpt-238410/'\n",
    "\n",
    "\n",
    "vocab_path = '../data/DMQA/finished_files/vocab'\n",
    "log_root = 'log'\n",
    "exp_name = 'myexperiment'\n",
    "data_path= 'test/temp_file'\n",
    "max_enc_steps = 4000\n",
    "\n",
    "cmd = ['python',\n",
    "       'run_summarization.py',\n",
    "       '--mode=decode',\n",
    "       '--single_pass=1',\n",
    "       '--coverage=True',\n",
    "       '--vocab_path=' + vocab_path,\n",
    "       '--log_root=' + log_root,\n",
    "       '--exp_name=' + exp_name,\n",
    "       '--data_path=' + data_path,\n",
    "       '--max_enc_steps=' + str(max_enc_steps)]\n",
    "\n",
    "generated_path = 'log/myexperiment/decode_test_4000maxenc_4beam_35mindec_100maxdec_ckpt-238410/'\n",
    "\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(string):\n",
    "    return ' '.join([stemmer.stem(word.decode('utf8')) for word in string.lower().split() if not word in stopwords])\n",
    "    \n",
    "def write_to_file(article, abstract, rel, writer):\n",
    "    abstract = '<s> '+' '.join(abstract)+' </s>'\n",
    "    #abstract = abstract.encode('utf8', 'ignore')\n",
    "    #rel = rel.encode('utf8', 'ignore')\n",
    "    #article = article.encode('utf8', 'ignore')\n",
    "    tf_example = example_pb2.Example()\n",
    "    tf_example.features.feature['abstract'].bytes_list.value.extend([bytes(abstract)])\n",
    "    tf_example.features.feature['relevancy'].bytes_list.value.extend([bytes(rel)])\n",
    "    tf_example.features.feature['article'].bytes_list.value.extend([bytes(article)])\n",
    "    tf_example_str = tf_example.SerializeToString()\n",
    "    str_len = len(tf_example_str)\n",
    "    writer.write(struct.pack('q', str_len))\n",
    "    writer.write(struct.pack('%ds' % str_len, tf_example_str))\n",
    "\n",
    "\n",
    "def duck_iterator(i):\n",
    "    duc_folder = 'duc0' + str(i) + 'tokenized/'\n",
    "    for topic in os.listdir(duc_folder + 'testdata/docs/'):\n",
    "        topic_folder = duc_folder + 'testdata/docs/' + topic\n",
    "        if not os.path.isdir(topic_folder):\n",
    "            continue\n",
    "        query = ' '.join(open(duc_folder + 'queries/' + topic).readlines())\n",
    "        model_files = glob(duc_folder + 'models/' + topic[:-1].upper() + '.*')\n",
    "\n",
    "        topic_texts = [' '.join(open(topic_folder + '/' + file).readlines()).replace('\\n', '') for file in\n",
    "                       os.listdir(topic_folder)]\n",
    "\n",
    "        abstracts = [' '.join(open(f).readlines()) for f in model_files]\n",
    "        yield topic_texts, abstracts, query\n",
    "\n",
    "def ones(sent, ref): return 1.\n",
    "\n",
    "def count_score(sent, ref):\n",
    "    ref = pp(ref).split()\n",
    "    sent = ' '.join(pp(w) for w in sent.lower().split() if not w in stopwords)\n",
    "    return sum([1. if w in ref else 0. for w in sent.split()])\n",
    "\n",
    "\n",
    "def get_w2v_score_func(magic = 10):\n",
    "    import gensim\n",
    "    google = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "        'GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    def w2v_score(sent, ref):\n",
    "        ref = ref.lower()\n",
    "        sent = sent.lower()\n",
    "        sent = [w for w in sent.split() if w in google]\n",
    "        ref = [w for w in ref.split() if w in google]\n",
    "        try:\n",
    "            score = google.n_similarity(sent, ref)\n",
    "        except:\n",
    "            score = 0.\n",
    "        return score * magic\n",
    "    return w2v_score\n",
    "\n",
    "def get_tfidf_score_func_glob(magic = 1):\n",
    "    corpus = []\n",
    "    for i in range(5, 8):\n",
    "        for topic_texts, _, _ in duck_iterator(i):\n",
    "            corpus += [pp(t) for t in topic_texts]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit_transform(corpus)\n",
    "\n",
    "    def tfidf_score_func(sent, ref):\n",
    "        #ref = [pp(s) for s in ref.split(' . ')]\n",
    "        sent = pp(sent)\n",
    "        v1 = vectorizer.transform([sent])\n",
    "        #v2s = [vectorizer.transform([r]) for r in ref]\n",
    "        #return max([cosine_similarity(v1, v2)[0][0] for v2 in v2s])\n",
    "        v2 = vectorizer.transform([ref])\n",
    "        return cosine_similarity(v1, v2)[0][0]\n",
    "\n",
    "    return tfidf_score_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_score = get_tfidf_score_func_glob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_score_func(magic = 10):\n",
    "    corpus = []\n",
    "    for i in range(5, 8):\n",
    "        for topic_texts, _, _ in duck_iterator(i):\n",
    "            corpus += [t.lower() for t in topic_texts]\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit_transform(corpus)\n",
    "\n",
    "    def tfidf_score_func(sent, ref):\n",
    "        ref = ref.lower()\n",
    "        sent = sent.lower()\n",
    "        v1 = vectorizer.transform([sent])\n",
    "        v2 = vectorizer.transform([ref])\n",
    "        return cosine_similarity(v1, v2)[0][0]*magic\n",
    "    return tfidf_score_func\n",
    "\n",
    "\n",
    "def just_relevant(text, query):\n",
    "    text = text.split(' . ')\n",
    "    score_per_sent = [count_score(sent, query) for sent in text]\n",
    "    sents_gold = list(zip(*sorted(zip(score_per_sent, text), reverse=True)))[1]\n",
    "    sents_gold = sents_gold[:int(len(sents_gold)*ratio)]\n",
    "\n",
    "    filtered_sents = []\n",
    "    for s in text:\n",
    "        if not s: continue\n",
    "        if s in sents_gold: filtered_sents.append(s)\n",
    "    return ' . '.join(filtered_sents)\n",
    "\n",
    "class Summary:\n",
    "    def __init__(self, texts, abstracts, query):\n",
    "        #texts = sorted([(tfidf_score(query, text), text) for text in texts], reverse=True)\n",
    "        #texts = sorted([(tfidf_score(text, ' '.join(abstracts)), text) for text in texts], reverse=True)\n",
    "\n",
    "        #texts = [text[1] for text in texts]\n",
    "        self.texts = texts\n",
    "        self.abstracts = abstracts\n",
    "        self.query = query\n",
    "        self.summary = []\n",
    "        self.words = set()\n",
    "        self.length = 0\n",
    "\n",
    "    def add_sum(self, summ):\n",
    "        for sent in summ:\n",
    "            self.summary.append(sent)\n",
    "\n",
    "    def get(self):\n",
    "        text = max([(len(t.split()), t) for t in  self.texts])[1]\n",
    "        #text = texts[0]\n",
    "        if ratio < 1: text = just_relevant(text, self.query)\n",
    "\n",
    "        sents = text.split(' . ')\n",
    "        score_per_sent = [(score_func(sent, self.query), sent) for sent in sents]\n",
    "        #score_per_sent = [(count_score(sent, ' '.join(self.abstracts)), sent) for sent in sents]\n",
    "\n",
    "        scores = []\n",
    "        for score, sent in score_per_sent:\n",
    "            scores += [score] * (len(sent.split()) + 1)\n",
    "        scores = str(scores[:-1])\n",
    "        return text, 'a', scores\n",
    "\n",
    "def get_summaries(path):\n",
    "    path = path+'decoded/'\n",
    "    out = {}\n",
    "    for file_name in os.listdir(path):\n",
    "        index = int(file_name.split('_')[0])\n",
    "        out[index] = open(path+file_name).readlines()\n",
    "    return out\n",
    "\n",
    "def rouge_eval(ref_dir, dec_dir):\n",
    "    \"\"\"Evaluate the files in ref_dir and dec_dir with pyrouge, returning results_dict\"\"\"\n",
    "    r = pyrouge.Rouge155()\n",
    "    r.model_filename_pattern = '#ID#_reference_(\\d+).txt'\n",
    "    r.system_filename_pattern = '(\\d+)_decoded.txt'\n",
    "    r.model_dir = ref_dir\n",
    "    r.system_dir = dec_dir\n",
    "    return r.convert_and_evaluate()\n",
    "\n",
    "def evaluate(summaries):\n",
    "    for path in ['eval/ref', 'eval/dec']:\n",
    "        if os.path.exists(path): shutil.rmtree(path, True)\n",
    "        os.mkdir(path)\n",
    "    for i, summ in enumerate(summaries):\n",
    "        for j,abs in enumerate(summ.abstracts):\n",
    "            with open('eval/ref/'+str(i)+'_reference_'+str(j)+'.txt', 'w') as f:\n",
    "                f.write(abs)\n",
    "        with open('eval/dec/'+str(i)+'_decoded.txt', 'w') as f:\n",
    "            f.write(' '.join(summ.summary))\n",
    "    print rouge_eval('eval/ref/', 'eval/dec/') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_score\n",
    "#score_func = ones#get_w2v_score_func()#get_tfidf_score_func()#count_score\n",
    "score_func = get_tfidf_score_func()\n",
    "\n",
    "summaries = [Summary(texts, abstracts, query) for texts, abstracts, query in duck_iterator(duc_num)]\n",
    "\n",
    "with open('test/temp_file', 'wb') as writer:\n",
    "    for summ in summaries:\n",
    "        article, abstract, scores = summ.get()\n",
    "        write_to_file(article, abstracts, scores, writer)\n",
    "call(['rm', '-r', generated_path])\n",
    "call(cmd)\n",
    "generated_summaries = get_summaries(generated_path)\n",
    "\n",
    "for i in range(len(summaries)):\n",
    "    summaries[i].add_sum(generated_summaries[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-05 12:52:11,913 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2019-02-05 12:52:11,916 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp_HYT1O/system and model files to /tmp/tmp_HYT1O/model.\n",
      "2019-02-05 12:52:11,917 [MainThread  ] [INFO ]  Processing files in eval/dec/.\n",
      "2019-02-05 12:52:11,918 [MainThread  ] [INFO ]  Processing 0_decoded.txt.\n",
      "2019-02-05 12:52:11,920 [MainThread  ] [INFO ]  Processing 1_decoded.txt.\n",
      "2019-02-05 12:52:11,921 [MainThread  ] [INFO ]  Processing 2_decoded.txt.\n",
      "2019-02-05 12:52:11,922 [MainThread  ] [INFO ]  Processing 3_decoded.txt.\n",
      "2019-02-05 12:52:11,924 [MainThread  ] [INFO ]  Processing 4_decoded.txt.\n",
      "2019-02-05 12:52:11,925 [MainThread  ] [INFO ]  Processing 5_decoded.txt.\n",
      "2019-02-05 12:52:11,927 [MainThread  ] [INFO ]  Processing 6_decoded.txt.\n",
      "2019-02-05 12:52:11,928 [MainThread  ] [INFO ]  Processing 7_decoded.txt.\n",
      "2019-02-05 12:52:11,930 [MainThread  ] [INFO ]  Processing 8_decoded.txt.\n",
      "2019-02-05 12:52:11,931 [MainThread  ] [INFO ]  Processing 9_decoded.txt.\n",
      "2019-02-05 12:52:11,933 [MainThread  ] [INFO ]  Processing 10_decoded.txt.\n",
      "2019-02-05 12:52:11,934 [MainThread  ] [INFO ]  Processing 11_decoded.txt.\n",
      "2019-02-05 12:52:11,935 [MainThread  ] [INFO ]  Processing 12_decoded.txt.\n",
      "2019-02-05 12:52:11,937 [MainThread  ] [INFO ]  Processing 13_decoded.txt.\n",
      "2019-02-05 12:52:11,938 [MainThread  ] [INFO ]  Processing 14_decoded.txt.\n",
      "2019-02-05 12:52:11,940 [MainThread  ] [INFO ]  Processing 15_decoded.txt.\n",
      "2019-02-05 12:52:11,941 [MainThread  ] [INFO ]  Processing 16_decoded.txt.\n",
      "2019-02-05 12:52:11,943 [MainThread  ] [INFO ]  Processing 17_decoded.txt.\n",
      "2019-02-05 12:52:11,944 [MainThread  ] [INFO ]  Processing 18_decoded.txt.\n",
      "2019-02-05 12:52:11,946 [MainThread  ] [INFO ]  Processing 19_decoded.txt.\n",
      "2019-02-05 12:52:11,947 [MainThread  ] [INFO ]  Processing 20_decoded.txt.\n",
      "2019-02-05 12:52:11,948 [MainThread  ] [INFO ]  Processing 21_decoded.txt.\n",
      "2019-02-05 12:52:11,950 [MainThread  ] [INFO ]  Processing 22_decoded.txt.\n",
      "2019-02-05 12:52:11,951 [MainThread  ] [INFO ]  Processing 23_decoded.txt.\n",
      "2019-02-05 12:52:11,953 [MainThread  ] [INFO ]  Processing 24_decoded.txt.\n",
      "2019-02-05 12:52:11,954 [MainThread  ] [INFO ]  Processing 25_decoded.txt.\n",
      "2019-02-05 12:52:11,956 [MainThread  ] [INFO ]  Processing 26_decoded.txt.\n",
      "2019-02-05 12:52:11,957 [MainThread  ] [INFO ]  Processing 27_decoded.txt.\n",
      "2019-02-05 12:52:11,959 [MainThread  ] [INFO ]  Processing 28_decoded.txt.\n",
      "2019-02-05 12:52:11,960 [MainThread  ] [INFO ]  Processing 29_decoded.txt.\n",
      "2019-02-05 12:52:11,962 [MainThread  ] [INFO ]  Processing 30_decoded.txt.\n",
      "2019-02-05 12:52:11,963 [MainThread  ] [INFO ]  Processing 31_decoded.txt.\n",
      "2019-02-05 12:52:11,965 [MainThread  ] [INFO ]  Processing 32_decoded.txt.\n",
      "2019-02-05 12:52:11,966 [MainThread  ] [INFO ]  Processing 33_decoded.txt.\n",
      "2019-02-05 12:52:11,967 [MainThread  ] [INFO ]  Processing 34_decoded.txt.\n",
      "2019-02-05 12:52:11,969 [MainThread  ] [INFO ]  Processing 35_decoded.txt.\n",
      "2019-02-05 12:52:11,970 [MainThread  ] [INFO ]  Processing 36_decoded.txt.\n",
      "2019-02-05 12:52:11,972 [MainThread  ] [INFO ]  Processing 37_decoded.txt.\n",
      "2019-02-05 12:52:11,973 [MainThread  ] [INFO ]  Processing 38_decoded.txt.\n",
      "2019-02-05 12:52:11,974 [MainThread  ] [INFO ]  Processing 39_decoded.txt.\n",
      "2019-02-05 12:52:11,976 [MainThread  ] [INFO ]  Processing 40_decoded.txt.\n",
      "2019-02-05 12:52:11,977 [MainThread  ] [INFO ]  Processing 41_decoded.txt.\n",
      "2019-02-05 12:52:11,979 [MainThread  ] [INFO ]  Processing 42_decoded.txt.\n",
      "2019-02-05 12:52:11,980 [MainThread  ] [INFO ]  Processing 43_decoded.txt.\n",
      "2019-02-05 12:52:11,981 [MainThread  ] [INFO ]  Processing 44_decoded.txt.\n",
      "2019-02-05 12:52:11,983 [MainThread  ] [INFO ]  Processing 45_decoded.txt.\n",
      "2019-02-05 12:52:11,984 [MainThread  ] [INFO ]  Processing 46_decoded.txt.\n",
      "2019-02-05 12:52:11,986 [MainThread  ] [INFO ]  Processing 47_decoded.txt.\n",
      "2019-02-05 12:52:11,987 [MainThread  ] [INFO ]  Processing 48_decoded.txt.\n",
      "2019-02-05 12:52:11,988 [MainThread  ] [INFO ]  Processing 49_decoded.txt.\n",
      "2019-02-05 12:52:11,990 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp_HYT1O/system.\n",
      "2019-02-05 12:52:11,991 [MainThread  ] [INFO ]  Processing files in eval/ref/.\n",
      "2019-02-05 12:52:11,992 [MainThread  ] [INFO ]  Processing 0_reference_0.txt.\n",
      "2019-02-05 12:52:11,994 [MainThread  ] [INFO ]  Processing 0_reference_1.txt.\n",
      "2019-02-05 12:52:11,995 [MainThread  ] [INFO ]  Processing 0_reference_2.txt.\n",
      "2019-02-05 12:52:11,997 [MainThread  ] [INFO ]  Processing 0_reference_3.txt.\n",
      "2019-02-05 12:52:11,998 [MainThread  ] [INFO ]  Processing 1_reference_0.txt.\n",
      "2019-02-05 12:52:12,000 [MainThread  ] [INFO ]  Processing 1_reference_1.txt.\n",
      "2019-02-05 12:52:12,001 [MainThread  ] [INFO ]  Processing 1_reference_2.txt.\n",
      "2019-02-05 12:52:12,003 [MainThread  ] [INFO ]  Processing 1_reference_3.txt.\n",
      "2019-02-05 12:52:12,004 [MainThread  ] [INFO ]  Processing 2_reference_0.txt.\n",
      "2019-02-05 12:52:12,005 [MainThread  ] [INFO ]  Processing 2_reference_1.txt.\n",
      "2019-02-05 12:52:12,007 [MainThread  ] [INFO ]  Processing 2_reference_2.txt.\n",
      "2019-02-05 12:52:12,008 [MainThread  ] [INFO ]  Processing 2_reference_3.txt.\n",
      "2019-02-05 12:52:12,010 [MainThread  ] [INFO ]  Processing 3_reference_0.txt.\n",
      "2019-02-05 12:52:12,011 [MainThread  ] [INFO ]  Processing 3_reference_1.txt.\n",
      "2019-02-05 12:52:12,013 [MainThread  ] [INFO ]  Processing 3_reference_2.txt.\n",
      "2019-02-05 12:52:12,014 [MainThread  ] [INFO ]  Processing 3_reference_3.txt.\n",
      "2019-02-05 12:52:12,016 [MainThread  ] [INFO ]  Processing 3_reference_4.txt.\n",
      "2019-02-05 12:52:12,017 [MainThread  ] [INFO ]  Processing 3_reference_5.txt.\n",
      "2019-02-05 12:52:12,019 [MainThread  ] [INFO ]  Processing 3_reference_6.txt.\n",
      "2019-02-05 12:52:12,020 [MainThread  ] [INFO ]  Processing 3_reference_7.txt.\n",
      "2019-02-05 12:52:12,022 [MainThread  ] [INFO ]  Processing 3_reference_8.txt.\n",
      "2019-02-05 12:52:12,023 [MainThread  ] [INFO ]  Processing 4_reference_0.txt.\n",
      "2019-02-05 12:52:12,025 [MainThread  ] [INFO ]  Processing 4_reference_1.txt.\n",
      "2019-02-05 12:52:12,026 [MainThread  ] [INFO ]  Processing 4_reference_2.txt.\n",
      "2019-02-05 12:52:12,028 [MainThread  ] [INFO ]  Processing 4_reference_3.txt.\n",
      "2019-02-05 12:52:12,029 [MainThread  ] [INFO ]  Processing 4_reference_4.txt.\n",
      "2019-02-05 12:52:12,030 [MainThread  ] [INFO ]  Processing 4_reference_5.txt.\n",
      "2019-02-05 12:52:12,032 [MainThread  ] [INFO ]  Processing 4_reference_6.txt.\n",
      "2019-02-05 12:52:12,033 [MainThread  ] [INFO ]  Processing 4_reference_7.txt.\n",
      "2019-02-05 12:52:12,035 [MainThread  ] [INFO ]  Processing 4_reference_8.txt.\n",
      "2019-02-05 12:52:12,036 [MainThread  ] [INFO ]  Processing 5_reference_0.txt.\n",
      "2019-02-05 12:52:12,038 [MainThread  ] [INFO ]  Processing 5_reference_1.txt.\n",
      "2019-02-05 12:52:12,039 [MainThread  ] [INFO ]  Processing 5_reference_2.txt.\n",
      "2019-02-05 12:52:12,040 [MainThread  ] [INFO ]  Processing 5_reference_3.txt.\n",
      "2019-02-05 12:52:12,042 [MainThread  ] [INFO ]  Processing 5_reference_4.txt.\n",
      "2019-02-05 12:52:12,043 [MainThread  ] [INFO ]  Processing 5_reference_5.txt.\n",
      "2019-02-05 12:52:12,045 [MainThread  ] [INFO ]  Processing 5_reference_6.txt.\n",
      "2019-02-05 12:52:12,046 [MainThread  ] [INFO ]  Processing 5_reference_7.txt.\n",
      "2019-02-05 12:52:12,048 [MainThread  ] [INFO ]  Processing 5_reference_8.txt.\n",
      "2019-02-05 12:52:12,049 [MainThread  ] [INFO ]  Processing 6_reference_0.txt.\n",
      "2019-02-05 12:52:12,051 [MainThread  ] [INFO ]  Processing 6_reference_1.txt.\n",
      "2019-02-05 12:52:12,052 [MainThread  ] [INFO ]  Processing 6_reference_2.txt.\n",
      "2019-02-05 12:52:12,054 [MainThread  ] [INFO ]  Processing 6_reference_3.txt.\n",
      "2019-02-05 12:52:12,055 [MainThread  ] [INFO ]  Processing 7_reference_0.txt.\n",
      "2019-02-05 12:52:12,057 [MainThread  ] [INFO ]  Processing 7_reference_1.txt.\n",
      "2019-02-05 12:52:12,058 [MainThread  ] [INFO ]  Processing 7_reference_2.txt.\n",
      "2019-02-05 12:52:12,060 [MainThread  ] [INFO ]  Processing 7_reference_3.txt.\n",
      "2019-02-05 12:52:12,061 [MainThread  ] [INFO ]  Processing 8_reference_0.txt.\n",
      "2019-02-05 12:52:12,063 [MainThread  ] [INFO ]  Processing 8_reference_1.txt.\n",
      "2019-02-05 12:52:12,064 [MainThread  ] [INFO ]  Processing 8_reference_2.txt.\n",
      "2019-02-05 12:52:12,066 [MainThread  ] [INFO ]  Processing 8_reference_3.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-05 12:52:12,067 [MainThread  ] [INFO ]  Processing 8_reference_4.txt.\n",
      "2019-02-05 12:52:12,069 [MainThread  ] [INFO ]  Processing 8_reference_5.txt.\n",
      "2019-02-05 12:52:12,070 [MainThread  ] [INFO ]  Processing 8_reference_6.txt.\n",
      "2019-02-05 12:52:12,071 [MainThread  ] [INFO ]  Processing 8_reference_7.txt.\n",
      "2019-02-05 12:52:12,073 [MainThread  ] [INFO ]  Processing 8_reference_8.txt.\n",
      "2019-02-05 12:52:12,074 [MainThread  ] [INFO ]  Processing 9_reference_0.txt.\n",
      "2019-02-05 12:52:12,076 [MainThread  ] [INFO ]  Processing 9_reference_1.txt.\n",
      "2019-02-05 12:52:12,077 [MainThread  ] [INFO ]  Processing 9_reference_2.txt.\n",
      "2019-02-05 12:52:12,079 [MainThread  ] [INFO ]  Processing 9_reference_3.txt.\n",
      "2019-02-05 12:52:12,080 [MainThread  ] [INFO ]  Processing 9_reference_4.txt.\n",
      "2019-02-05 12:52:12,082 [MainThread  ] [INFO ]  Processing 9_reference_5.txt.\n",
      "2019-02-05 12:52:12,083 [MainThread  ] [INFO ]  Processing 9_reference_6.txt.\n",
      "2019-02-05 12:52:12,085 [MainThread  ] [INFO ]  Processing 9_reference_7.txt.\n",
      "2019-02-05 12:52:12,086 [MainThread  ] [INFO ]  Processing 9_reference_8.txt.\n",
      "2019-02-05 12:52:12,088 [MainThread  ] [INFO ]  Processing 10_reference_0.txt.\n",
      "2019-02-05 12:52:12,089 [MainThread  ] [INFO ]  Processing 10_reference_1.txt.\n",
      "2019-02-05 12:52:12,091 [MainThread  ] [INFO ]  Processing 10_reference_2.txt.\n",
      "2019-02-05 12:52:12,092 [MainThread  ] [INFO ]  Processing 10_reference_3.txt.\n",
      "2019-02-05 12:52:12,094 [MainThread  ] [INFO ]  Processing 11_reference_0.txt.\n",
      "2019-02-05 12:52:12,095 [MainThread  ] [INFO ]  Processing 11_reference_1.txt.\n",
      "2019-02-05 12:52:12,097 [MainThread  ] [INFO ]  Processing 11_reference_2.txt.\n",
      "2019-02-05 12:52:12,098 [MainThread  ] [INFO ]  Processing 11_reference_3.txt.\n",
      "2019-02-05 12:52:12,100 [MainThread  ] [INFO ]  Processing 12_reference_0.txt.\n",
      "2019-02-05 12:52:12,101 [MainThread  ] [INFO ]  Processing 12_reference_1.txt.\n",
      "2019-02-05 12:52:12,103 [MainThread  ] [INFO ]  Processing 12_reference_2.txt.\n",
      "2019-02-05 12:52:12,104 [MainThread  ] [INFO ]  Processing 12_reference_3.txt.\n",
      "2019-02-05 12:52:12,106 [MainThread  ] [INFO ]  Processing 13_reference_0.txt.\n",
      "2019-02-05 12:52:12,107 [MainThread  ] [INFO ]  Processing 13_reference_1.txt.\n",
      "2019-02-05 12:52:12,109 [MainThread  ] [INFO ]  Processing 13_reference_2.txt.\n",
      "2019-02-05 12:52:12,110 [MainThread  ] [INFO ]  Processing 13_reference_3.txt.\n",
      "2019-02-05 12:52:12,112 [MainThread  ] [INFO ]  Processing 14_reference_0.txt.\n",
      "2019-02-05 12:52:12,113 [MainThread  ] [INFO ]  Processing 14_reference_1.txt.\n",
      "2019-02-05 12:52:12,114 [MainThread  ] [INFO ]  Processing 14_reference_2.txt.\n",
      "2019-02-05 12:52:12,116 [MainThread  ] [INFO ]  Processing 14_reference_3.txt.\n",
      "2019-02-05 12:52:12,117 [MainThread  ] [INFO ]  Processing 14_reference_4.txt.\n",
      "2019-02-05 12:52:12,119 [MainThread  ] [INFO ]  Processing 14_reference_5.txt.\n",
      "2019-02-05 12:52:12,120 [MainThread  ] [INFO ]  Processing 14_reference_6.txt.\n",
      "2019-02-05 12:52:12,122 [MainThread  ] [INFO ]  Processing 14_reference_7.txt.\n",
      "2019-02-05 12:52:12,123 [MainThread  ] [INFO ]  Processing 14_reference_8.txt.\n",
      "2019-02-05 12:52:12,125 [MainThread  ] [INFO ]  Processing 15_reference_0.txt.\n",
      "2019-02-05 12:52:12,126 [MainThread  ] [INFO ]  Processing 15_reference_1.txt.\n",
      "2019-02-05 12:52:12,128 [MainThread  ] [INFO ]  Processing 15_reference_2.txt.\n",
      "2019-02-05 12:52:12,129 [MainThread  ] [INFO ]  Processing 15_reference_3.txt.\n",
      "2019-02-05 12:52:12,131 [MainThread  ] [INFO ]  Processing 15_reference_4.txt.\n",
      "2019-02-05 12:52:12,132 [MainThread  ] [INFO ]  Processing 15_reference_5.txt.\n",
      "2019-02-05 12:52:12,133 [MainThread  ] [INFO ]  Processing 15_reference_6.txt.\n",
      "2019-02-05 12:52:12,135 [MainThread  ] [INFO ]  Processing 15_reference_7.txt.\n",
      "2019-02-05 12:52:12,136 [MainThread  ] [INFO ]  Processing 15_reference_8.txt.\n",
      "2019-02-05 12:52:12,138 [MainThread  ] [INFO ]  Processing 16_reference_0.txt.\n",
      "2019-02-05 12:52:12,139 [MainThread  ] [INFO ]  Processing 16_reference_1.txt.\n",
      "2019-02-05 12:52:12,141 [MainThread  ] [INFO ]  Processing 16_reference_2.txt.\n",
      "2019-02-05 12:52:12,142 [MainThread  ] [INFO ]  Processing 16_reference_3.txt.\n",
      "2019-02-05 12:52:12,144 [MainThread  ] [INFO ]  Processing 17_reference_0.txt.\n",
      "2019-02-05 12:52:12,145 [MainThread  ] [INFO ]  Processing 17_reference_1.txt.\n",
      "2019-02-05 12:52:12,146 [MainThread  ] [INFO ]  Processing 17_reference_2.txt.\n",
      "2019-02-05 12:52:12,148 [MainThread  ] [INFO ]  Processing 17_reference_3.txt.\n",
      "2019-02-05 12:52:12,149 [MainThread  ] [INFO ]  Processing 18_reference_0.txt.\n",
      "2019-02-05 12:52:12,151 [MainThread  ] [INFO ]  Processing 18_reference_1.txt.\n",
      "2019-02-05 12:52:12,152 [MainThread  ] [INFO ]  Processing 18_reference_2.txt.\n",
      "2019-02-05 12:52:12,154 [MainThread  ] [INFO ]  Processing 18_reference_3.txt.\n",
      "2019-02-05 12:52:12,155 [MainThread  ] [INFO ]  Processing 19_reference_0.txt.\n",
      "2019-02-05 12:52:12,156 [MainThread  ] [INFO ]  Processing 19_reference_1.txt.\n",
      "2019-02-05 12:52:12,158 [MainThread  ] [INFO ]  Processing 19_reference_2.txt.\n",
      "2019-02-05 12:52:12,159 [MainThread  ] [INFO ]  Processing 19_reference_3.txt.\n",
      "2019-02-05 12:52:12,161 [MainThread  ] [INFO ]  Processing 19_reference_4.txt.\n",
      "2019-02-05 12:52:12,162 [MainThread  ] [INFO ]  Processing 19_reference_5.txt.\n",
      "2019-02-05 12:52:12,164 [MainThread  ] [INFO ]  Processing 19_reference_6.txt.\n",
      "2019-02-05 12:52:12,165 [MainThread  ] [INFO ]  Processing 19_reference_7.txt.\n",
      "2019-02-05 12:52:12,167 [MainThread  ] [INFO ]  Processing 19_reference_8.txt.\n",
      "2019-02-05 12:52:12,168 [MainThread  ] [INFO ]  Processing 20_reference_0.txt.\n",
      "2019-02-05 12:52:12,170 [MainThread  ] [INFO ]  Processing 20_reference_1.txt.\n",
      "2019-02-05 12:52:12,171 [MainThread  ] [INFO ]  Processing 20_reference_2.txt.\n",
      "2019-02-05 12:52:12,173 [MainThread  ] [INFO ]  Processing 20_reference_3.txt.\n",
      "2019-02-05 12:52:12,174 [MainThread  ] [INFO ]  Processing 20_reference_4.txt.\n",
      "2019-02-05 12:52:12,175 [MainThread  ] [INFO ]  Processing 20_reference_5.txt.\n",
      "2019-02-05 12:52:12,177 [MainThread  ] [INFO ]  Processing 20_reference_6.txt.\n",
      "2019-02-05 12:52:12,179 [MainThread  ] [INFO ]  Processing 20_reference_7.txt.\n",
      "2019-02-05 12:52:12,180 [MainThread  ] [INFO ]  Processing 20_reference_8.txt.\n",
      "2019-02-05 12:52:12,181 [MainThread  ] [INFO ]  Processing 21_reference_0.txt.\n",
      "2019-02-05 12:52:12,183 [MainThread  ] [INFO ]  Processing 21_reference_1.txt.\n",
      "2019-02-05 12:52:12,185 [MainThread  ] [INFO ]  Processing 21_reference_2.txt.\n",
      "2019-02-05 12:52:12,186 [MainThread  ] [INFO ]  Processing 21_reference_3.txt.\n",
      "2019-02-05 12:52:12,188 [MainThread  ] [INFO ]  Processing 22_reference_0.txt.\n",
      "2019-02-05 12:52:12,189 [MainThread  ] [INFO ]  Processing 22_reference_1.txt.\n",
      "2019-02-05 12:52:12,190 [MainThread  ] [INFO ]  Processing 22_reference_2.txt.\n",
      "2019-02-05 12:52:12,192 [MainThread  ] [INFO ]  Processing 22_reference_3.txt.\n",
      "2019-02-05 12:52:12,193 [MainThread  ] [INFO ]  Processing 23_reference_0.txt.\n",
      "2019-02-05 12:52:12,195 [MainThread  ] [INFO ]  Processing 23_reference_1.txt.\n",
      "2019-02-05 12:52:12,196 [MainThread  ] [INFO ]  Processing 23_reference_2.txt.\n",
      "2019-02-05 12:52:12,197 [MainThread  ] [INFO ]  Processing 23_reference_3.txt.\n",
      "2019-02-05 12:52:12,199 [MainThread  ] [INFO ]  Processing 23_reference_4.txt.\n",
      "2019-02-05 12:52:12,200 [MainThread  ] [INFO ]  Processing 23_reference_5.txt.\n",
      "2019-02-05 12:52:12,202 [MainThread  ] [INFO ]  Processing 23_reference_6.txt.\n",
      "2019-02-05 12:52:12,203 [MainThread  ] [INFO ]  Processing 23_reference_7.txt.\n",
      "2019-02-05 12:52:12,204 [MainThread  ] [INFO ]  Processing 23_reference_8.txt.\n",
      "2019-02-05 12:52:12,206 [MainThread  ] [INFO ]  Processing 24_reference_0.txt.\n",
      "2019-02-05 12:52:12,207 [MainThread  ] [INFO ]  Processing 24_reference_1.txt.\n",
      "2019-02-05 12:52:12,209 [MainThread  ] [INFO ]  Processing 24_reference_2.txt.\n",
      "2019-02-05 12:52:12,210 [MainThread  ] [INFO ]  Processing 24_reference_3.txt.\n",
      "2019-02-05 12:52:12,212 [MainThread  ] [INFO ]  Processing 24_reference_4.txt.\n",
      "2019-02-05 12:52:12,213 [MainThread  ] [INFO ]  Processing 24_reference_5.txt.\n",
      "2019-02-05 12:52:12,215 [MainThread  ] [INFO ]  Processing 24_reference_6.txt.\n",
      "2019-02-05 12:52:12,216 [MainThread  ] [INFO ]  Processing 24_reference_7.txt.\n",
      "2019-02-05 12:52:12,218 [MainThread  ] [INFO ]  Processing 24_reference_8.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-05 12:52:12,219 [MainThread  ] [INFO ]  Processing 25_reference_0.txt.\n",
      "2019-02-05 12:52:12,221 [MainThread  ] [INFO ]  Processing 25_reference_1.txt.\n",
      "2019-02-05 12:52:12,222 [MainThread  ] [INFO ]  Processing 25_reference_2.txt.\n",
      "2019-02-05 12:52:12,224 [MainThread  ] [INFO ]  Processing 25_reference_3.txt.\n",
      "2019-02-05 12:52:12,225 [MainThread  ] [INFO ]  Processing 26_reference_0.txt.\n",
      "2019-02-05 12:52:12,227 [MainThread  ] [INFO ]  Processing 26_reference_1.txt.\n",
      "2019-02-05 12:52:12,228 [MainThread  ] [INFO ]  Processing 26_reference_2.txt.\n",
      "2019-02-05 12:52:12,230 [MainThread  ] [INFO ]  Processing 26_reference_3.txt.\n",
      "2019-02-05 12:52:12,231 [MainThread  ] [INFO ]  Processing 27_reference_0.txt.\n",
      "2019-02-05 12:52:12,232 [MainThread  ] [INFO ]  Processing 27_reference_1.txt.\n",
      "2019-02-05 12:52:12,234 [MainThread  ] [INFO ]  Processing 27_reference_2.txt.\n",
      "2019-02-05 12:52:12,236 [MainThread  ] [INFO ]  Processing 27_reference_3.txt.\n",
      "2019-02-05 12:52:12,237 [MainThread  ] [INFO ]  Processing 27_reference_4.txt.\n",
      "2019-02-05 12:52:12,238 [MainThread  ] [INFO ]  Processing 27_reference_5.txt.\n",
      "2019-02-05 12:52:12,240 [MainThread  ] [INFO ]  Processing 27_reference_6.txt.\n",
      "2019-02-05 12:52:12,241 [MainThread  ] [INFO ]  Processing 27_reference_7.txt.\n",
      "2019-02-05 12:52:12,243 [MainThread  ] [INFO ]  Processing 27_reference_8.txt.\n",
      "2019-02-05 12:52:12,244 [MainThread  ] [INFO ]  Processing 28_reference_0.txt.\n",
      "2019-02-05 12:52:12,246 [MainThread  ] [INFO ]  Processing 28_reference_1.txt.\n",
      "2019-02-05 12:52:12,247 [MainThread  ] [INFO ]  Processing 28_reference_2.txt.\n",
      "2019-02-05 12:52:12,249 [MainThread  ] [INFO ]  Processing 28_reference_3.txt.\n",
      "2019-02-05 12:52:12,250 [MainThread  ] [INFO ]  Processing 28_reference_4.txt.\n",
      "2019-02-05 12:52:12,252 [MainThread  ] [INFO ]  Processing 28_reference_5.txt.\n",
      "2019-02-05 12:52:12,253 [MainThread  ] [INFO ]  Processing 28_reference_6.txt.\n",
      "2019-02-05 12:52:12,254 [MainThread  ] [INFO ]  Processing 28_reference_7.txt.\n",
      "2019-02-05 12:52:12,256 [MainThread  ] [INFO ]  Processing 28_reference_8.txt.\n",
      "2019-02-05 12:52:12,258 [MainThread  ] [INFO ]  Processing 29_reference_0.txt.\n",
      "2019-02-05 12:52:12,259 [MainThread  ] [INFO ]  Processing 29_reference_1.txt.\n",
      "2019-02-05 12:52:12,261 [MainThread  ] [INFO ]  Processing 29_reference_2.txt.\n",
      "2019-02-05 12:52:12,262 [MainThread  ] [INFO ]  Processing 29_reference_3.txt.\n",
      "2019-02-05 12:52:12,264 [MainThread  ] [INFO ]  Processing 30_reference_0.txt.\n",
      "2019-02-05 12:52:12,265 [MainThread  ] [INFO ]  Processing 30_reference_1.txt.\n",
      "2019-02-05 12:52:12,266 [MainThread  ] [INFO ]  Processing 30_reference_2.txt.\n",
      "2019-02-05 12:52:12,268 [MainThread  ] [INFO ]  Processing 30_reference_3.txt.\n",
      "2019-02-05 12:52:12,269 [MainThread  ] [INFO ]  Processing 31_reference_0.txt.\n",
      "2019-02-05 12:52:12,271 [MainThread  ] [INFO ]  Processing 31_reference_1.txt.\n",
      "2019-02-05 12:52:12,272 [MainThread  ] [INFO ]  Processing 31_reference_2.txt.\n",
      "2019-02-05 12:52:12,274 [MainThread  ] [INFO ]  Processing 31_reference_3.txt.\n",
      "2019-02-05 12:52:12,275 [MainThread  ] [INFO ]  Processing 32_reference_0.txt.\n",
      "2019-02-05 12:52:12,277 [MainThread  ] [INFO ]  Processing 32_reference_1.txt.\n",
      "2019-02-05 12:52:12,278 [MainThread  ] [INFO ]  Processing 32_reference_2.txt.\n",
      "2019-02-05 12:52:12,279 [MainThread  ] [INFO ]  Processing 32_reference_3.txt.\n",
      "2019-02-05 12:52:12,281 [MainThread  ] [INFO ]  Processing 33_reference_0.txt.\n",
      "2019-02-05 12:52:12,282 [MainThread  ] [INFO ]  Processing 33_reference_1.txt.\n",
      "2019-02-05 12:52:12,284 [MainThread  ] [INFO ]  Processing 33_reference_2.txt.\n",
      "2019-02-05 12:52:12,285 [MainThread  ] [INFO ]  Processing 33_reference_3.txt.\n",
      "2019-02-05 12:52:12,287 [MainThread  ] [INFO ]  Processing 34_reference_0.txt.\n",
      "2019-02-05 12:52:12,288 [MainThread  ] [INFO ]  Processing 34_reference_1.txt.\n",
      "2019-02-05 12:52:12,290 [MainThread  ] [INFO ]  Processing 34_reference_2.txt.\n",
      "2019-02-05 12:52:12,291 [MainThread  ] [INFO ]  Processing 34_reference_3.txt.\n",
      "2019-02-05 12:52:12,293 [MainThread  ] [INFO ]  Processing 35_reference_0.txt.\n",
      "2019-02-05 12:52:12,294 [MainThread  ] [INFO ]  Processing 35_reference_1.txt.\n",
      "2019-02-05 12:52:12,296 [MainThread  ] [INFO ]  Processing 35_reference_2.txt.\n",
      "2019-02-05 12:52:12,297 [MainThread  ] [INFO ]  Processing 35_reference_3.txt.\n",
      "2019-02-05 12:52:12,299 [MainThread  ] [INFO ]  Processing 36_reference_0.txt.\n",
      "2019-02-05 12:52:12,300 [MainThread  ] [INFO ]  Processing 36_reference_1.txt.\n",
      "2019-02-05 12:52:12,302 [MainThread  ] [INFO ]  Processing 36_reference_2.txt.\n",
      "2019-02-05 12:52:12,303 [MainThread  ] [INFO ]  Processing 36_reference_3.txt.\n",
      "2019-02-05 12:52:12,304 [MainThread  ] [INFO ]  Processing 36_reference_4.txt.\n",
      "2019-02-05 12:52:12,306 [MainThread  ] [INFO ]  Processing 36_reference_5.txt.\n",
      "2019-02-05 12:52:12,308 [MainThread  ] [INFO ]  Processing 36_reference_6.txt.\n",
      "2019-02-05 12:52:12,309 [MainThread  ] [INFO ]  Processing 36_reference_7.txt.\n",
      "2019-02-05 12:52:12,310 [MainThread  ] [INFO ]  Processing 36_reference_8.txt.\n",
      "2019-02-05 12:52:12,312 [MainThread  ] [INFO ]  Processing 37_reference_0.txt.\n",
      "2019-02-05 12:52:12,313 [MainThread  ] [INFO ]  Processing 37_reference_1.txt.\n",
      "2019-02-05 12:52:12,315 [MainThread  ] [INFO ]  Processing 37_reference_2.txt.\n",
      "2019-02-05 12:52:12,316 [MainThread  ] [INFO ]  Processing 37_reference_3.txt.\n",
      "2019-02-05 12:52:12,318 [MainThread  ] [INFO ]  Processing 37_reference_4.txt.\n",
      "2019-02-05 12:52:12,319 [MainThread  ] [INFO ]  Processing 37_reference_5.txt.\n",
      "2019-02-05 12:52:12,321 [MainThread  ] [INFO ]  Processing 37_reference_6.txt.\n",
      "2019-02-05 12:52:12,322 [MainThread  ] [INFO ]  Processing 37_reference_7.txt.\n",
      "2019-02-05 12:52:12,324 [MainThread  ] [INFO ]  Processing 37_reference_8.txt.\n",
      "2019-02-05 12:52:12,325 [MainThread  ] [INFO ]  Processing 38_reference_0.txt.\n",
      "2019-02-05 12:52:12,327 [MainThread  ] [INFO ]  Processing 38_reference_1.txt.\n",
      "2019-02-05 12:52:12,328 [MainThread  ] [INFO ]  Processing 38_reference_2.txt.\n",
      "2019-02-05 12:52:12,330 [MainThread  ] [INFO ]  Processing 38_reference_3.txt.\n",
      "2019-02-05 12:52:12,331 [MainThread  ] [INFO ]  Processing 39_reference_0.txt.\n",
      "2019-02-05 12:52:12,332 [MainThread  ] [INFO ]  Processing 39_reference_1.txt.\n",
      "2019-02-05 12:52:12,334 [MainThread  ] [INFO ]  Processing 39_reference_2.txt.\n",
      "2019-02-05 12:52:12,335 [MainThread  ] [INFO ]  Processing 39_reference_3.txt.\n",
      "2019-02-05 12:52:12,336 [MainThread  ] [INFO ]  Processing 39_reference_4.txt.\n",
      "2019-02-05 12:52:12,338 [MainThread  ] [INFO ]  Processing 39_reference_5.txt.\n",
      "2019-02-05 12:52:12,340 [MainThread  ] [INFO ]  Processing 39_reference_6.txt.\n",
      "2019-02-05 12:52:12,341 [MainThread  ] [INFO ]  Processing 39_reference_7.txt.\n",
      "2019-02-05 12:52:12,343 [MainThread  ] [INFO ]  Processing 39_reference_8.txt.\n",
      "2019-02-05 12:52:12,344 [MainThread  ] [INFO ]  Processing 40_reference_0.txt.\n",
      "2019-02-05 12:52:12,346 [MainThread  ] [INFO ]  Processing 40_reference_1.txt.\n",
      "2019-02-05 12:52:12,347 [MainThread  ] [INFO ]  Processing 40_reference_2.txt.\n",
      "2019-02-05 12:52:12,348 [MainThread  ] [INFO ]  Processing 40_reference_3.txt.\n",
      "2019-02-05 12:52:12,350 [MainThread  ] [INFO ]  Processing 41_reference_0.txt.\n",
      "2019-02-05 12:52:12,352 [MainThread  ] [INFO ]  Processing 41_reference_1.txt.\n",
      "2019-02-05 12:52:12,353 [MainThread  ] [INFO ]  Processing 41_reference_2.txt.\n",
      "2019-02-05 12:52:12,354 [MainThread  ] [INFO ]  Processing 41_reference_3.txt.\n",
      "2019-02-05 12:52:12,356 [MainThread  ] [INFO ]  Processing 41_reference_4.txt.\n",
      "2019-02-05 12:52:12,357 [MainThread  ] [INFO ]  Processing 41_reference_5.txt.\n",
      "2019-02-05 12:52:12,359 [MainThread  ] [INFO ]  Processing 41_reference_6.txt.\n",
      "2019-02-05 12:52:12,360 [MainThread  ] [INFO ]  Processing 41_reference_7.txt.\n",
      "2019-02-05 12:52:12,362 [MainThread  ] [INFO ]  Processing 41_reference_8.txt.\n",
      "2019-02-05 12:52:12,363 [MainThread  ] [INFO ]  Processing 42_reference_0.txt.\n",
      "2019-02-05 12:52:12,365 [MainThread  ] [INFO ]  Processing 42_reference_1.txt.\n",
      "2019-02-05 12:52:12,366 [MainThread  ] [INFO ]  Processing 42_reference_2.txt.\n",
      "2019-02-05 12:52:12,368 [MainThread  ] [INFO ]  Processing 42_reference_3.txt.\n",
      "2019-02-05 12:52:12,369 [MainThread  ] [INFO ]  Processing 43_reference_0.txt.\n",
      "2019-02-05 12:52:12,370 [MainThread  ] [INFO ]  Processing 43_reference_1.txt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-05 12:52:12,372 [MainThread  ] [INFO ]  Processing 43_reference_2.txt.\n",
      "2019-02-05 12:52:12,373 [MainThread  ] [INFO ]  Processing 43_reference_3.txt.\n",
      "2019-02-05 12:52:12,375 [MainThread  ] [INFO ]  Processing 43_reference_4.txt.\n",
      "2019-02-05 12:52:12,376 [MainThread  ] [INFO ]  Processing 43_reference_5.txt.\n",
      "2019-02-05 12:52:12,377 [MainThread  ] [INFO ]  Processing 43_reference_6.txt.\n",
      "2019-02-05 12:52:12,379 [MainThread  ] [INFO ]  Processing 43_reference_7.txt.\n",
      "2019-02-05 12:52:12,381 [MainThread  ] [INFO ]  Processing 43_reference_8.txt.\n",
      "2019-02-05 12:52:12,382 [MainThread  ] [INFO ]  Processing 44_reference_0.txt.\n",
      "2019-02-05 12:52:12,384 [MainThread  ] [INFO ]  Processing 44_reference_1.txt.\n",
      "2019-02-05 12:52:12,385 [MainThread  ] [INFO ]  Processing 44_reference_2.txt.\n",
      "2019-02-05 12:52:12,387 [MainThread  ] [INFO ]  Processing 44_reference_3.txt.\n",
      "2019-02-05 12:52:12,388 [MainThread  ] [INFO ]  Processing 44_reference_4.txt.\n",
      "2019-02-05 12:52:12,390 [MainThread  ] [INFO ]  Processing 44_reference_5.txt.\n",
      "2019-02-05 12:52:12,391 [MainThread  ] [INFO ]  Processing 44_reference_6.txt.\n",
      "2019-02-05 12:52:12,393 [MainThread  ] [INFO ]  Processing 44_reference_7.txt.\n",
      "2019-02-05 12:52:12,394 [MainThread  ] [INFO ]  Processing 44_reference_8.txt.\n",
      "2019-02-05 12:52:12,396 [MainThread  ] [INFO ]  Processing 45_reference_0.txt.\n",
      "2019-02-05 12:52:12,397 [MainThread  ] [INFO ]  Processing 45_reference_1.txt.\n",
      "2019-02-05 12:52:12,399 [MainThread  ] [INFO ]  Processing 45_reference_2.txt.\n",
      "2019-02-05 12:52:12,401 [MainThread  ] [INFO ]  Processing 45_reference_3.txt.\n",
      "2019-02-05 12:52:12,402 [MainThread  ] [INFO ]  Processing 46_reference_0.txt.\n",
      "2019-02-05 12:52:12,403 [MainThread  ] [INFO ]  Processing 46_reference_1.txt.\n",
      "2019-02-05 12:52:12,405 [MainThread  ] [INFO ]  Processing 46_reference_2.txt.\n",
      "2019-02-05 12:52:12,406 [MainThread  ] [INFO ]  Processing 46_reference_3.txt.\n",
      "2019-02-05 12:52:12,408 [MainThread  ] [INFO ]  Processing 47_reference_0.txt.\n",
      "2019-02-05 12:52:12,409 [MainThread  ] [INFO ]  Processing 47_reference_1.txt.\n",
      "2019-02-05 12:52:12,411 [MainThread  ] [INFO ]  Processing 47_reference_2.txt.\n",
      "2019-02-05 12:52:12,412 [MainThread  ] [INFO ]  Processing 47_reference_3.txt.\n",
      "2019-02-05 12:52:12,414 [MainThread  ] [INFO ]  Processing 48_reference_0.txt.\n",
      "2019-02-05 12:52:12,416 [MainThread  ] [INFO ]  Processing 48_reference_1.txt.\n",
      "2019-02-05 12:52:12,417 [MainThread  ] [INFO ]  Processing 48_reference_2.txt.\n",
      "2019-02-05 12:52:12,419 [MainThread  ] [INFO ]  Processing 48_reference_3.txt.\n",
      "2019-02-05 12:52:12,420 [MainThread  ] [INFO ]  Processing 48_reference_4.txt.\n",
      "2019-02-05 12:52:12,421 [MainThread  ] [INFO ]  Processing 48_reference_5.txt.\n",
      "2019-02-05 12:52:12,423 [MainThread  ] [INFO ]  Processing 48_reference_6.txt.\n",
      "2019-02-05 12:52:12,424 [MainThread  ] [INFO ]  Processing 48_reference_7.txt.\n",
      "2019-02-05 12:52:12,426 [MainThread  ] [INFO ]  Processing 48_reference_8.txt.\n",
      "2019-02-05 12:52:12,427 [MainThread  ] [INFO ]  Processing 49_reference_0.txt.\n",
      "2019-02-05 12:52:12,429 [MainThread  ] [INFO ]  Processing 49_reference_1.txt.\n",
      "2019-02-05 12:52:12,430 [MainThread  ] [INFO ]  Processing 49_reference_2.txt.\n",
      "2019-02-05 12:52:12,431 [MainThread  ] [INFO ]  Processing 49_reference_3.txt.\n",
      "2019-02-05 12:52:12,433 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp_HYT1O/model.\n",
      "2019-02-05 12:52:12,460 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpSDkP4t/rouge_conf.xml\n",
      "2019-02-05 12:52:12,461 [MainThread  ] [INFO ]  Running ROUGE with command /home/stephaneg/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/stephaneg/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpSDkP4t/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.07374 (95%-conf.int. 0.06623 - 0.08103)\n",
      "1 ROUGE-1 Average_P: 0.37283 (95%-conf.int. 0.34603 - 0.39877)\n",
      "1 ROUGE-1 Average_F: 0.12228 (95%-conf.int. 0.11071 - 0.13356)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.01022 (95%-conf.int. 0.00780 - 0.01278)\n",
      "1 ROUGE-2 Average_P: 0.05141 (95%-conf.int. 0.04119 - 0.06170)\n",
      "1 ROUGE-2 Average_F: 0.01693 (95%-conf.int. 0.01308 - 0.02088)\n",
      "---------------------------------------------\n",
      "1 ROUGE-3 Average_R: 0.00213 (95%-conf.int. 0.00117 - 0.00328)\n",
      "1 ROUGE-3 Average_P: 0.01049 (95%-conf.int. 0.00627 - 0.01537)\n",
      "1 ROUGE-3 Average_F: 0.00351 (95%-conf.int. 0.00196 - 0.00536)\n",
      "---------------------------------------------\n",
      "1 ROUGE-4 Average_R: 0.00076 (95%-conf.int. 0.00022 - 0.00145)\n",
      "1 ROUGE-4 Average_P: 0.00333 (95%-conf.int. 0.00107 - 0.00614)\n",
      "1 ROUGE-4 Average_F: 0.00123 (95%-conf.int. 0.00036 - 0.00234)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.06804 (95%-conf.int. 0.06101 - 0.07469)\n",
      "1 ROUGE-L Average_P: 0.34460 (95%-conf.int. 0.31877 - 0.36938)\n",
      "1 ROUGE-L Average_F: 0.11285 (95%-conf.int. 0.10202 - 0.12332)\n",
      "---------------------------------------------\n",
      "1 ROUGE-W-1.2 Average_R: 0.02286 (95%-conf.int. 0.02077 - 0.02482)\n",
      "1 ROUGE-W-1.2 Average_P: 0.21641 (95%-conf.int. 0.20227 - 0.23025)\n",
      "1 ROUGE-W-1.2 Average_F: 0.04117 (95%-conf.int. 0.03764 - 0.04444)\n",
      "---------------------------------------------\n",
      "1 ROUGE-S* Average_R: 0.00612 (95%-conf.int. 0.00494 - 0.00739)\n",
      "1 ROUGE-S* Average_P: 0.14872 (95%-conf.int. 0.13084 - 0.16772)\n",
      "1 ROUGE-S* Average_F: 0.01167 (95%-conf.int. 0.00947 - 0.01401)\n",
      "---------------------------------------------\n",
      "1 ROUGE-SU* Average_R: 0.00665 (95%-conf.int. 0.00542 - 0.00798)\n",
      "1 ROUGE-SU* Average_P: 0.15798 (95%-conf.int. 0.14004 - 0.17702)\n",
      "1 ROUGE-SU* Average_F: 0.01266 (95%-conf.int. 0.01038 - 0.01511)\n",
      "\n",
      "5\n",
      "<function tfidf_score_func at 0x7f2387f19b90>\n"
     ]
    }
   ],
   "source": [
    "evaluate(summaries)\n",
    "print duc_num\n",
    "print score_func "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
